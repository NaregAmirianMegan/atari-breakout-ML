# atari-breakout-ML
Use reinforcement learning to train computer to play Atari Breakout.

# DQN with Experience Replay algorithm from DeepMind
Initialize replay memory D to capacity N </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initialize action-value function Q with random weights </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for episode = 1, M do </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initialise sequence s1 = {x1} and preprocessed sequenced Ï†1 = Ï†(s1) </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for t = 1, T do </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;With probability  select a random action at </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;otherwise select at = maxa Qâˆ—(Ï†(st), a; Î¸) </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Execute action at in emulator and observe reward rt and image xt+1 </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set st+1 = st, at, xt+1 and preprocess Ï†t+1 = Ï†(st+1) </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Store transition (Ï†t, at, rt, Ï†t+1) in D </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sample random minibatch of transitions (Ï†j , aj , rj , Ï†j+1) from D </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set yj = rj for terminal Ï†j+1 </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set yj = rj + Î³ maxa0 Q(Ï†j+1, a0; Î¸) for non-terminal Ï†j+1 </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Perform a gradient descent step on (yj âˆ’ Q(Ï†j , aj ; Î¸))2 </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;according to equation 3 </br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;end for </br>
end for </br>
